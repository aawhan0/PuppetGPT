# ğŸ¤– RAG-Powered PDF Chatbot

A beginner-friendly AI chatbot that uses **Retrieval-Augmented Generation (RAG)** to answer questions strictly based on an uploaded PDF. Built with **Streamlit**, **LangChain**, **Groqâ€™s LLaMA 3**, and **HuggingFace embeddings**, this project showcases how to build a smart assistant that doesnâ€™t rely on the web â€” only on what *you* give it.

---

## ğŸš€ Features

- ğŸ“¤ Upload any PDF
- ğŸ’¬ Ask questions from the PDF
- ğŸ§  AI answers only using the provided document
- ğŸ˜ Fun manipulator persona (customizable!)
- âš¡ Fast responses via Groq LLaMA 3
- ğŸ–¥ï¸ Clean UI with Streamlit

---

## ğŸ§  Tech Stack

- **Python**
- **Streamlit** â€“ Web interface
- **LangChain** â€“ LLM app framework
- **Groq API** â€“ Fast inference with LLaMA 3
- **HuggingFace BGE Embeddings** â€“ For text vectorization
- **ChromaDB** â€“ Lightweight vector store
- **dotenv** â€“ For managing API keys

---

## âš™ï¸ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/your-username/rag-pdf-chatbot.git
cd rag-pdf-chatbot
```

### 2. Install the dependencies

```bash
pip install -r requirements.txt
```

### 3. Add your Groq API key
Create a .env file in the root directory:

``` ini

GROQ_API_KEY=your_groq_api_key
```
You can rename .env.example to .env and fill in your key.

### 4. Run the app
```bash
streamlit run app.py
```

## ğŸ“ Project Structure
```bash
rag-pdf-chatbot/
â”œâ”€â”€ app.py               # Main Streamlit app
â”œâ”€â”€ requirements.txt     # Project dependencies
â”œâ”€â”€ .env.example         # Example environment config
â”œâ”€â”€ README.md            # Project overview
â”œâ”€â”€ docs/                # Optional: screenshots or demo
â””â”€â”€ uploaded_docs/       # Folder for your PDFs
```

## ğŸ¬ Demo
https://www.linkedin.com/posts/aawhanvyas_ai-python-langchain-activity-7339601558700969984-I5at?utm_source=social_share_send&utm_medium=member_desktop_web&rcm=ACoAADaRDxMBlgfFkMQLV1Rpkmjb4yG3lBUiSjs


## ğŸ’¡ How it Works
The chatbot uses RAG (Retrieval-Augmented Generation) â€” it breaks down your PDF into chunks, embeds them using HuggingFace, stores them in a vector database, and then uses Groqâ€™s LLaMA 3 model to answer your questions based on what it finds in the PDF. No hallucinations from the web â€” only facts from your document.

## ğŸ“œ License
This project is licensed under the MIT License.

## ğŸ™ Acknowledgements
Groq

LangChain

Streamlit

HuggingFace

Chroma
